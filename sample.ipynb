{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd552b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2  # OpenCVã§å‹•ç”»ã¨ç”»åƒå‡¦ç†\n",
    "import torch  # PyTorchã§YOLOv5ãƒ¢ãƒ‡ãƒ«åˆ©ç”¨\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e404c14",
   "metadata": {},
   "source": [
    "### 1. YOLOv5ãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b4e47ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5 ğŸš€ v7.0-429-g50313d30 Python-3.11.13 torch-2.2.2 CPU\n",
      "\n",
      "Fusing layers... \n",
      "[W NNPACK.cpp:64] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients, 16.4 GFLOPs\n",
      "Adding AutoShape... \n"
     ]
    }
   ],
   "source": [
    "# ========= 1. YOLOv5ãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ‰ =========\n",
    "#   yolov5s.ptã¯è‡ªå‹•ã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¾ã™\n",
    "#   deviceã‚’'cpu'ã«æ˜ç¤ºã™ã‚‹ã“ã¨ã§CPUå°‚ç”¨å®Ÿè¡Œã«ãªã‚Šã¾ã™\n",
    "model = torch.hub.load(\n",
    "    './yolov5',          # ã‚¯ãƒ­ãƒ¼ãƒ³ã—ãŸYOLOv5ãƒªãƒã‚¸ãƒˆãƒªã®ãƒ‘ã‚¹\n",
    "    'custom',            # ã‚«ã‚¹ã‚¿ãƒ ãƒ¢ãƒ‡ãƒ«ï¼ˆyolov5sç­‰ã‚‚å¯ï¼‰\n",
    "    path='yolov5s.pt',   # å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§OKï¼‰\n",
    "    source='local',      # ãƒ­ãƒ¼ã‚«ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦èª­ã¿è¾¼ã‚€\n",
    "    device='cpu'         # CPUå¼·åˆ¶\n",
    ")\n",
    "\n",
    "# ãƒ©ãƒ™ãƒ«ï¼ˆäººã€è»Šâ€¦ãªã©ã®åå‰ãƒªã‚¹ãƒˆï¼‰\n",
    "class_names = model.names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e94758b9",
   "metadata": {},
   "source": [
    "### 2. å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f6e858f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ========= 2. å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ =========\n",
    "video_path = 'data/nihonbashi-short-mini.mp4'\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "if not cap.isOpened():\n",
    "    print(\"å‹•ç”»ãŒé–‹ã‘ã¾ã›ã‚“ã€‚ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚\")\n",
    "    sys.exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670fb08b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a9e21f2c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d531e0ae",
   "metadata": {},
   "source": [
    "### 3. æ¨è«–ï¼ˆç‰©ä½“æ¤œå‡ºï¼‰"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdded038",
   "metadata": {},
   "source": [
    "YOLOv5ã®æ¨å®š(modelãƒ¡ã‚½ãƒƒãƒ‰)ã®è¿”ã‚Šå€¤ã«ã¤ã„ã¦ï¼ˆGPTã®è§£èª¬ï¼‰\n",
    "- å‹:  yolov5.utils.general.Detections\n",
    "- åº§æ¨™å½¢å¼ã”ã¨ã® Tensor ã‚’è¿”ã™\n",
    "    - results.xyxy\n",
    "        [x1, y1, x2, y2, conf, cls] ï¼ˆå·¦ä¸Šã¨å³ä¸‹ã®åº§æ¨™ï¼‰\n",
    "        \n",
    "        | index  | å†…å®¹                                  |\n",
    "        | ------ | ------------------------------------- |\n",
    "        | 0      | `x1` ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹ã®å·¦ä¸Šã® xåº§æ¨™ |\n",
    "        | 1      | `y1` ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹ã®å·¦ä¸Šã® yåº§æ¨™ |\n",
    "        | 2      | `x2` ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹ã®å³ä¸‹ã® xåº§æ¨™ |\n",
    "        | 3      | `y2` ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹ã®å³ä¸‹ã® yåº§æ¨™ |\n",
    "        | 4      | `conf` æ¤œå‡ºç¢ºä¿¡åº¦ (confidence score)       |\n",
    "        | 5      | `cls` ã‚¯ãƒ©ã‚¹IDï¼ˆ0=person, 1=bicycle, ...ï¼‰ | \n",
    "        <br>\n",
    "    - results.xywh\n",
    "        [x_center, y_center, width, height, conf, cls]\n",
    "   \n",
    "        | index  | å†…å®¹                                  |\n",
    "        | ------ | ------------------------------------- |\n",
    "        | 0      | `x_center` ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹ã®ä¸­å¿ƒã® xåº§æ¨™ |\n",
    "        | 1      | `y_center` ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹ã®ä¸­å¿ƒã® yåº§æ¨™ |\n",
    "        | 2      | `width` ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹ã®å¹…|\n",
    "        | 3      | `height` ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹ã®é«˜ã• |\n",
    "        | 4      | `conf` æ¤œå‡ºç¢ºä¿¡åº¦ (confidence score)       |\n",
    "        | 5      | `cls` ã‚¯ãƒ©ã‚¹IDï¼ˆ0=person, 1=bicycle, ...ï¼‰ |\n",
    "\n",
    "    - results.xyxyn / results.xywhn\n",
    "        ä¸Šè¨˜ã‚’ç”»åƒã‚µã‚¤ã‚ºã§ 0ã€œ1ã«æ­£è¦åŒ–ã—ãŸå€¤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2bc2d7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recognition(frame):\n",
    "    results = model(frame[..., ::-1])  # YOLOv5ã«ç”»åƒã‚’æ¸¡ã—ã¦æ¤œå‡º\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0065671",
   "metadata": {},
   "source": [
    "### 4. çµæœã‚’ãƒ•ãƒ¬ãƒ¼ãƒ ã«æç”»"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d980ef28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_info_on_mov(results, frame):\n",
    "    for *box, conf, cls in results.xyxy[0].tolist():\n",
    "        # åº§æ¨™ã¨ãƒ©ãƒ™ãƒ«\n",
    "        x1, y1, x2, y2 = map(int, box)\n",
    "        label = class_names[int(cls)]\n",
    "        score = float(conf)\n",
    "        # æ¤œå‡ºæ \n",
    "        cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "        # ãƒ©ãƒ™ãƒ«\n",
    "        cv2.putText(\n",
    "            frame,\n",
    "            f\"{label}: {score:.2f}\",\n",
    "            (x1, y1 - 10),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX,\n",
    "            0.7,\n",
    "            (0, 255, 0),\n",
    "            2\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85fe192b",
   "metadata": {},
   "source": [
    "### æç”»ãƒ«ãƒ¼ãƒ—"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cadbadf",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mç¾åœ¨ã®ã‚»ãƒ«ã¾ãŸã¯å‰ã®ã‚»ãƒ«ã§ã‚³ãƒ¼ãƒ‰ã‚’å®Ÿè¡Œä¸­ã«ã€ã‚«ãƒ¼ãƒãƒ« (Kernel) ãŒã‚¯ãƒ©ãƒƒã‚·ãƒ¥ã—ã¾ã—ãŸã€‚\n",
      "\u001b[1;31mã‚¨ãƒ©ãƒ¼ã®åŸå› ã‚’ç‰¹å®šã™ã‚‹ã«ã¯ã€ã‚»ãƒ«å†…ã®ã‚³ãƒ¼ãƒ‰ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚\n",
      "\u001b[1;31mè©³ç´°ã«ã¤ã„ã¦ã¯<a href='https://aka.ms/vscodeJupyterKernelCrash'>ã“ã¡ã‚‰</a>ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¾ã™ã€‚\n",
      "\u001b[1;31mè©³ç´°ã«ã¤ã„ã¦ã¯ã€Jupyter <a href='command:jupyter.viewOutput'>ãƒ­ã‚°</a> ã‚’å‚ç…§ã—ã¦ãã ã•ã„ã€‚"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break  # å‹•ç”»ã®æœ€å¾Œã§ãƒ«ãƒ¼ãƒ—çµ‚äº†\n",
    "\n",
    "    # ========= 3. æ¨è«–ï¼ˆç‰©ä½“æ¤œå‡ºï¼‰ =========\n",
    "    # OpenCVã¯BGRâ‡’YOLOã¯RGB\n",
    "    results = recognition(frame)\n",
    "    \n",
    "    # ========= 4. çµæœã‚’ãƒ•ãƒ¬ãƒ¼ãƒ ã«æç”» =========\n",
    "    # å„ç‰©ä½“ã”ã¨ã«æ¤œå‡ºãƒœãƒƒã‚¯ã‚¹ï¼†ãƒ©ãƒ™ãƒ«ã‚’è¿½åŠ \n",
    "    draw_info_on_mov(results, frame)\n",
    "    \n",
    "    # ========= 5. ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦è¡¨ç¤º =========\n",
    "    cv2.imshow(\"YOLOv5 Detection\", frame)\n",
    "    # qã‚­ãƒ¼ã§é€”ä¸­çµ‚äº†\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# ========= 6. å¾Œå‡¦ç† =========\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2dbb53c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# å…¥åŠ›å‹•ç”»ã‚’é–‹ã\n",
    "cap = cv2.VideoCapture(\"./data/shinjuku.mp4\")\n",
    "\n",
    "# å‹•ç”»ã®æƒ…å ±ã‚’å–å¾—\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)                       # ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¬ãƒ¼ãƒˆ\n",
    "width  = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))       # æ¨ªå¹…\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))      # ç¸¦å¹…\n",
    "size = (width, height)\n",
    "\n",
    "# å‡ºåŠ›è¨­å®šï¼ˆãƒ•ã‚¡ã‚¤ãƒ«å, FourCC, FPS, ã‚µã‚¤ã‚ºï¼‰\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # MP4å½¢å¼\n",
    "out = cv2.VideoWriter(\"output.mp4\", fourcc, fps, size)\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # ã“ã“ã§å‡¦ç†ã‚’åŠ ãˆã‚‹ã“ã¨ã‚‚å¯èƒ½\n",
    "    # ä¾‹: ã‚°ãƒ¬ãƒ¼ã‚¹ã‚±ãƒ¼ãƒ«ã«å¤‰æ›ï¼ˆä¿å­˜ã¯ã‚«ãƒ©ãƒ¼æŒ‡å®šãªã®ã§BGRã«æˆ»ã™å¿…è¦ã‚ã‚Šï¼‰\n",
    "    # gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    # frame = cv2.cvtColor(gray, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "    out.write(frame)  # ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’æ›¸ãè¾¼ã¿\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "# cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "906e33fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
