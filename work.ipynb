{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd1584b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2  # OpenCVで動画と画像処理\n",
    "import torch  # PyTorchでYOLOv5モデル利用\n",
    "import sys\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.manifold import MDS\n",
    "import matplotlib.pyplot as plt\n",
    "import colorsys\n",
    "from tqdm.notebook import tqdm\n",
    "import warnings\n",
    "import math\n",
    "from itertools import combinations\n",
    "import random\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1bbd79f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5 🚀 v7.0-425-g85acef3a Python-3.12.3 torch-2.8.0+cpu CPU\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients, 16.4 GFLOPs\n",
      "Adding AutoShape... \n"
     ]
    }
   ],
   "source": [
    "# ========= YOLOv5モデルのロード =========\n",
    "#   yolov5s.ptは自動でダウンロードされます\n",
    "#   deviceを'cpu'に明示することでCPU専用実行になります\n",
    "yolo_model = torch.hub.load(\n",
    "    './yolov5',          # クローンしたYOLOv5リポジトリのパス\n",
    "    'custom',            # カスタムモデル（yolov5s等も可）\n",
    "    path='yolov5s.pt',   # 学習済みモデル（デフォルトでOK）\n",
    "    source='local',      # ローカルファイルとして読み込む\n",
    "    device='cpu'         # CPU強制\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60333c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_object_sim_dict(obj_dict):\n",
    "    # ラベル（人、車…などの名前リスト）\n",
    "    labels_list = list(obj_dict.values())\n",
    "\n",
    "    # ================= Embedding =================\n",
    "    model = SentenceTransformer('all-MiniLM-L6-v2', device='cpu')\n",
    "    embeddings = model.encode(labels_list, convert_to_numpy=True)\n",
    "\n",
    "    # ================= 類似度 → 距離 =================\n",
    "    # cosine類似度\n",
    "    def cosine_sim(a, b):\n",
    "        return np.dot(a, b) / (np.linalg.norm(a)*np.linalg.norm(b))\n",
    "\n",
    "    n = len(labels_list)\n",
    "    sim_matrix = np.zeros((n,n))\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            sim_matrix[i,j] = cosine_sim(embeddings[i], embeddings[j])\n",
    "\n",
    "    # 類似度 → 距離に変換（1-類似度）\n",
    "    dist_matrix = 1 - sim_matrix\n",
    "\n",
    "    # ================= MDSで2D座標に埋め込み =================\n",
    "    mds = MDS(n_components=2, dissimilarity='precomputed', random_state=42)\n",
    "    coords = mds.fit_transform(dist_matrix)  # shape = (n_labels, 2)\n",
    "\n",
    "    # ================= 座標 → 角度 =================\n",
    "    # 中心を原点に移動\n",
    "    coords_centered = coords - coords.mean(axis=0)\n",
    "    angles_rad = np.arctan2(coords_centered[:,1], coords_centered[:,0])\n",
    "\n",
    "    class_names = {}\n",
    "    base_angle_rad = angles_rad[0]\n",
    "    target_angle_rad = np.radians(210)\n",
    "    angles_rad_rotated = angles_rad + (target_angle_rad - base_angle_rad)\n",
    "    angles_deg_rotated = (np.degrees(angles_rad_rotated) + 360) % 360\n",
    "    for (k, v), angle in tqdm(zip(obj_dict.items(), angles_deg_rotated)):\n",
    "        class_names[int(k)] = {\n",
    "            'label': v,\n",
    "            'degree': float(angle)\n",
    "        }\n",
    "    return class_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1ad3679",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_class_sim(class_names):\n",
    "    data = class_names.values()\n",
    "    # 半径\n",
    "    r = 1.0  \n",
    "    points = []\n",
    "    colors = []\n",
    "\n",
    "    # 座標計算と色付け\n",
    "    for item in data:\n",
    "        theta = np.deg2rad(item['degree'])\n",
    "        x, y = r * np.cos(theta), r * np.sin(theta)\n",
    "        points.append((x, y))\n",
    "        rgb = colorsys.hsv_to_rgb(item['degree']/360.0, 1.0, 1.0)\n",
    "        colors.append(rgb)\n",
    "\n",
    "    # 描画\n",
    "    fig, ax = plt.subplots(figsize=(6,6))\n",
    "    ax.set_aspect('equal')\n",
    "    ax.axis('off')\n",
    "\n",
    "    # 円\n",
    "    circle = plt.Circle((0,0), r, color='lightgray', fill=False, linestyle='--')\n",
    "    ax.add_artist(circle)\n",
    "\n",
    "    # 点 + ラベル\n",
    "    for (x, y), c, item in zip(points, colors, data):\n",
    "        ax.plot(x, y, 'o', color=c, markersize=12)\n",
    "        ax.text(x*1.15, y*1.15, item['label'], ha='center', va='center')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9290c530",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 近傍の3点を探し出す\n",
    "def distance(p1, p2):\n",
    "    \"\"\"2点間のユークリッド距離（x, yのみ使用）\"\"\"\n",
    "    return math.sqrt((p1[0] - p2[0])**2 + (p1[1] - p2[1])**2)\n",
    "\n",
    "def total_distance(triplet):\n",
    "    \"\"\"3点の合計距離\"\"\"\n",
    "    return distance(triplet[0], triplet[1]) + distance(triplet[0], triplet[2]) + distance(triplet[1], triplet[2])\n",
    "\n",
    "def find_nearest_triplets(points):\n",
    "    points = points.copy()\n",
    "    triplets = []\n",
    "\n",
    "    while len(points) >= 3:\n",
    "        min_dist = float('inf')\n",
    "        nearest_triplet = None\n",
    "\n",
    "        # 3点の組み合わせをすべてチェック\n",
    "        for comb in combinations(range(len(points)), 3):\n",
    "            triplet = [points[comb[0]], points[comb[1]], points[comb[2]]]\n",
    "            d = total_distance(triplet)\n",
    "            if d < min_dist:\n",
    "                min_dist = d\n",
    "                nearest_triplet = comb\n",
    "\n",
    "        # 見つけたトリプレットを記録\n",
    "        triplets.append((points[nearest_triplet[0]], points[nearest_triplet[1]], points[nearest_triplet[2]]))\n",
    "        # 使用済みの点を削除（インデックスが大きい順）\n",
    "        for index in sorted(nearest_triplet, reverse=True):\n",
    "            points.pop(index)\n",
    "\n",
    "    return triplets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0320587d",
   "metadata": {},
   "source": [
    "- 可視化表現の設計\n",
    "\n",
    "- 使えそうな入力変数\n",
    "    - xc, yc -> 物体の中心\n",
    "    - w -> 幅\n",
    "    - h -> 高さ\n",
    "    - score -> 信頼度\n",
    "    - label -> 識別名\n",
    "    - cls -> labelのインデックス\n",
    "\n",
    "\n",
    "- 視覚変数\n",
    "    - 位置：xc,yc\n",
    "    - 色相: cls\n",
    "    - 明度: \n",
    "    - 彩度: \n",
    "    - 透明度: \n",
    "    - "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b01e4bf4",
   "metadata": {},
   "source": [
    "opencvで使える画像メソッド\n",
    "\n",
    "| 図形       | メソッド                                                                            | 主な引数                                                                          | 簡単な使い方                                                                                                     |\n",
    "| -------- | ------------------------------------------------------------------------------- | ----------------------------------------------------------------------------- | ---------------------------------------------------------------------------------------------------------- |\n",
    "| 線        | `cv2.line(img, pt1, pt2, color, thickness)`                                     | `pt1=(x1,y1)`, `pt2=(x2,y2)`, `color=(B,G,R)`, `thickness=線の太さ`               | `cv2.line(img, (50,50), (200,50), (0,255,0), 3)`                                                           |\n",
    "| 矩形（四角形）  | `cv2.rectangle(img, pt1, pt2, color, thickness)`                                | `pt1=(左上x,左上y)`, `pt2=(右下x,右下y)`, `thickness=-1で塗りつぶし`                        | `cv2.rectangle(img, (50,50), (200,150), (255,0,0), 2)`                                                     |\n",
    "| 円        | `cv2.circle(img, center, radius, color, thickness)`                             | `center=(x,y)`, `radius=半径`, `thickness=-1で塗りつぶし`                             | `cv2.circle(img, (150,150), 40, (0,0,255), -1)`                                                            |\n",
    "| 楕円       | `cv2.ellipse(img, center, axes, angle, startAngle, endAngle, color, thickness)` | `center=(x,y)`, `axes=(長径/2, 短径/2)`, `angle=回転角度`, `startAngle/endAngle=描く範囲` | `cv2.ellipse(img, (200,200), (80,40), 30, 0, 360, (255,255,0), 2)`                                         |\n",
    "| 多角形      | `cv2.polylines(img, [pts], isClosed, color, thickness)`                         | `pts = numpy.array([[x1,y1],[x2,y2],...], np.int32)`                          | `pts = np.array([[100,50],[200,150],[50,150]], np.int32); cv2.polylines(img, [pts], True, (0,255,255), 2)` |\n",
    "| 塗りつぶし多角形 | `cv2.fillPoly(img, [pts], color)`                                               | `pts` は上と同じ                                                                   | `cv2.fillPoly(img, [pts], (0,128,255))`                                                                    |\n",
    "| 文字       | `cv2.putText(img, text, org, font, fontScale, color, thickness)`                | `org=(x,y)`, `font=cv2.FONT_HERSHEY_SIMPLEX` など                               | `cv2.putText(img, \"Hello\", (50,250), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 2)`                       |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fca0dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_object_name_dict(cap):\n",
    "    obj_list = {}\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    for _ in tqdm(range(total_frames)):\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break  # 動画の最後でループ終了\n",
    "        \n",
    "        results = yolo_model(frame[..., ::-1])  # YOLOv5に画像を渡して検出\n",
    "        for *box, conf, cls in results.xywh[0].tolist():\n",
    "            obj_list[int(cls)] = yolo_model.names[int(cls)]\n",
    "            \n",
    "    return obj_list\n",
    "\n",
    "def hsv2bgr(h, s, v):\n",
    "    # HSV色 (H=60°, S=255, V=255)\n",
    "    hsv_color = np.uint8([[[h, s, v]]])  # OpenCVはH:0-179, S/V:0-255\n",
    "    bgr_color = cv2.cvtColor(hsv_color, cv2.COLOR_HSV2BGR)[0][0]\n",
    "    return tuple(int(c) for c in bgr_color)\n",
    "\n",
    "def draw_info_on_mov(result_hist, frame, crnt_frame_num, class_names):\n",
    "    alpha = 0.5\n",
    "    height, width = frame.shape[:2]\n",
    "    transparent_layer = np.zeros((height, width, 3), dtype=np.uint8)\n",
    "    \n",
    "    for result_dict in result_hist:\n",
    "        results = result_dict['results']\n",
    "        frame_num = result_dict['frame_num']\n",
    "        pos_list = []\n",
    "        for *box, conf, cls in results.xywh[0].tolist():\n",
    "            # 座標とラベル\n",
    "            cx, cy, w, h = map(int, box)\n",
    "            label = class_names[int(cls)]['label']\n",
    "            score = float(conf)\n",
    "\n",
    "            damping_coef = (frame_num / crnt_frame_num) ** 3\n",
    "            r = int(np.min([w, h]) * 0.3 * damping_coef)\n",
    "            hue = class_names[int(cls)]['degree'] / 2   # cv2では[0,180]で指定する\n",
    "            saturation = 255 * 0.9 * damping_coef\n",
    "            brightness = (255 - 100) * score  + 100\n",
    "            \n",
    "            # 検出枠\n",
    "            color = hsv2bgr(hue, saturation, brightness)\n",
    "            cv2.circle(transparent_layer, (cx, cy), r, color, -1)\n",
    "            cv2.circle(frame, (cx, cy), r, color, 1)\n",
    "\n",
    "            # テキスト\n",
    "            if frame_num == crnt_frame_num:\n",
    "                text = f'{\"\\n\".join(str.capitalize(label))}\\n{score:.2f}'\n",
    "                x0 = int(cx - r)\n",
    "                y0 = int(cy - h/2)\n",
    "                dy = 30\n",
    "                for i, char in enumerate(reversed(text.split(\"\\n\"))):\n",
    "                    y = y0 - i*dy\n",
    "                    x = x0 + 20 if len(char) == 1 else x0\n",
    "                    cv2.putText(frame, char, (x, y), cv2.FONT_HERSHEY_TRIPLEX, 1, (255,255,255), 1)\n",
    "\n",
    "                # 3角形を書くために一時保存\n",
    "                pos_list.append((cx, cy, r))\n",
    "        \n",
    "        if frame_num == crnt_frame_num:\n",
    "            # 最新フレームで3近傍を取得\n",
    "            triplets = find_nearest_triplets(pos_list)\n",
    "            for t in triplets:\n",
    "                pos = []\n",
    "                for (cx, cy, r) in t:\n",
    "                    t = random.uniform(0, 2*math.pi)\n",
    "                    x = int(cx + r * math.cos(t))\n",
    "                    y = int(cy + r * math.sin(t))\n",
    "                    cv2.line(frame, (cx, cy), (x, y),  (255,255,255), 1)\n",
    "                    pos.append((x,y))\n",
    "                cv2.line(frame, pos[0], pos[1], (255,255,255), 1)\n",
    "                cv2.line(frame, pos[1], pos[2], (255,255,255), 1)\n",
    "                cv2.line(frame, pos[2], pos[0], (255,255,255), 1)\n",
    "        \n",
    "        display_frame = cv2.addWeighted(frame, 1.0, transparent_layer, alpha, 0)\n",
    "    return display_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b8d562ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "動画読み込み完了:data/shinjuku.mp4\n",
      "動画書き出し準備完了:out/output.mp4\n"
     ]
    }
   ],
   "source": [
    "# ========= 動画ファイルの読み込み =========\n",
    "video_path = 'data/shinjuku.mp4' # 例：'input.mp4'  カメラなら 0\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "if not cap.isOpened():\n",
    "    print(\"動画が開けません。ファイルパスを確認してください。\")\n",
    "    sys.exit(1)\n",
    "print(f'動画読み込み完了:{video_path}')\n",
    "\n",
    "# ========= 動画ファイルの書き出し設定 =========\n",
    "# 出力設定（例: MP4, 30fps, 元の解像度）\n",
    "out_path = \"out/output.mp4\"\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "w = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "h = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "out = cv2.VideoWriter(out_path, fourcc, fps, (w, h))\n",
    "print(f'動画書き出し準備完了:{out_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b4dcf099",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "識別物体の事前検出と類似度計算\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9086dd9f3cad48f9a08a1b8f50395b74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/425 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b636306955fc40cb9f4d29db10d2c087",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ========= 事前の物体識別 =========\n",
    "print('識別物体の事前検出と類似度計算')\n",
    "cap.set(cv2.CAP_PROP_POS_FRAMES, 0) # 最初に戻す\n",
    "obj_dict = get_object_name_dict(cap)\n",
    "class_names = get_object_sim_dict(obj_dict)\n",
    "draw_class_sim(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "aa75a882",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ========= 描画開始 =========\n",
    "cap.set(cv2.CAP_PROP_POS_FRAMES, 0) # 最初に戻す\n",
    "result_hist = []\n",
    "while True:\n",
    "    # ========= フレーム取得 ========= \n",
    "    ret, frame = cap.read()\n",
    "    frame_num = int(cap.get(cv2.CAP_PROP_POS_FRAMES))\n",
    "    crnt_frame_num = frame_num\n",
    "    if not ret:\n",
    "        break  # 動画の最後でループ終了\n",
    "\n",
    "    # ========= 推論（物体検出） =========\n",
    "    # OpenCVはBGR⇒YOLOはRGB\n",
    "    results = yolo_model(frame[..., ::-1])  # YOLOv5に画像を渡して検出\n",
    "    result_hist.append({'results':results, 'frame_num': frame_num})\n",
    "    \n",
    "    # ========= 結果をフレームに描画 =========\n",
    "    # 動画はグレースケール化\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    gray_frame = cv2.cvtColor(gray, cv2.COLOR_GRAY2BGR)\n",
    "    \n",
    "    # ========= 視覚表現の追加 ========= \n",
    "    display_frame = draw_info_on_mov(result_hist[-30:], gray_frame, crnt_frame_num, class_names)\n",
    "    \n",
    "    # ========= ウィンドウ表示 =========\n",
    "    cv2.imshow(\"YOLOv5 Detection\", display_frame)\n",
    "\n",
    "    # ========= フレームを書き込み ========= \n",
    "    out.write(display_frame) \n",
    "\n",
    "    # ========= qキーで途中終了 ========= \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "    \n",
    "# ========= 後処理 =========\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e8fd32e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class_names = get_object_sim_dict(obj_dict)\n",
    "# draw_class_sim(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "be807c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# m = math.exp(1)\n",
    "# n = math.log(0.1)\n",
    "# for a in [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]:\n",
    "#     print(a, math.exp(a) / m, 1 - math.log(a) / n )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e838980",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
